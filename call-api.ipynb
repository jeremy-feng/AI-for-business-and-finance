{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dashscope\n",
    "import openai\n",
    "from chatllm.llmchain.llms import ChatGLM, ErnieBot, SparkBot\n",
    "from dashscope import Generation\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Model API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a total of 5 large model APIs, which are:\n",
    "\n",
    "- OpenAI API, see https://api.nextweb.fun/ and https://flowus.cn/yifei/share/7c1ff13b-277d-40da-8c04-ebf770ea46ea\n",
    "- Xunfei Spark API（讯飞星火）, see https://console.xfyun.cn/services/cbm\n",
    "- Zhipu AI API（智谱 AI）, see https://open.bigmodel.cn/usercenter/apikeys\n",
    "- Baidu API（百度千帆）, see https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application\n",
    "- Alibaba Tongyi Qianwen API（阿里通义千问）, see https://dashscope.console.aliyun.com/apiKey\n",
    "\n",
    "You can register an account and apply for an API Key for each of the above URLs. Most models offer a certain amount of free quota for new users, while a few may require prepayment.\n",
    "\n",
    "To avoid exposing the API Keys in public code, we will store the API Keys in a `.env` file and then load them into environment variables using the `load_dotenv()` method from the `dotenv` package.\n",
    "\n",
    "Create a new `.env` file in the current directory with the following structure:\n",
    "\n",
    "```\n",
    ".\n",
    "├── .env\n",
    "└── call-api.ipynb\n",
    "```\n",
    "\n",
    "The content of the `.env` file is as follows:\n",
    "\n",
    "```\n",
    "OPENAI_API_BASE=https://api.nextweb.fun/openai/v1\n",
    "OPENAI_API_KEY=ak-XXXXXX\n",
    "SPARK_API_KEY={APP Id}:{API Key}:{Secret Key}\n",
    "CHATGLM_API_KEY={API Key}\n",
    "ERNIE_API_KEY={API Key}:{Secret Key}\n",
    "DASHSCOPE_API_KEY=sk-XXXXXX\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Environment Variables Using the `dotenv` Package\n",
    "load_dotenv()\n",
    "\n",
    "# The following three variables are somewhat special, and we need to set them manually, otherwise errors may occur\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "dashscope.api_key = os.environ['DASHSCOPE_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up instances of conversational AI for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "# Set up instances of chatbots for each model\n",
    "llm_spark = SparkBot()\n",
    "llm_zhipuai = ChatGLM()\n",
    "llm_ernie = ErnieBot()\n",
    "\n",
    "# Create chat instances for each chatbot model\n",
    "chat_spark = LLMChain(llm=llm_spark, prompt=prompt)\n",
    "chat_zhipuai = LLMChain(llm=llm_zhipuai, prompt=prompt)\n",
    "chat_ernie = LLMChain(llm=llm_ernie, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the conversation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Who are you?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a language model AI created by OpenAI, here to assist and answer your questions to the best of my abilities.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        ).choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xunfei Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am iFLYTEK Spark developed by iFLYTEK, and myHello, I am iFLYTEK Spark developed by iFLYTEK, and my name is iFLYTEK Spark. I can communicate with human beings naturally, answer questions, and efficiently complete the needs of cognitive intelligence in various fields.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_spark.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhipu AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am an AI assistant named ChatGLM2-6B, which is developed based on the language model jointly trained by Tsinghua University KEG Lab and Zhipu AI Company in 2023. My job is to provide appropriate answers and support to users' questions and requests.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_zhipuai.run(prompt)[1:-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baidu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我是由百度公司开发的人工智能语言模型，我叫文心一言。我的知识来自于训练数据和算法，不具备个人身份和实体。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_ernie.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alibaba Tongyi Qianwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a large language model created by Alibaba Cloud. I am called QianWen.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generation.call(model=\"qwen-turbo\", prompt=prompt).output.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
